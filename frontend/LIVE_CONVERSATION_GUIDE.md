# ğŸ™ï¸ Live 2-Way Conversation Demo

**Real-time voice conversation with AI using STT â†’ LLM â†’ TTS pipeline**

---

## ğŸ“‹ Overview

The Live Conversation feature creates a natural, continuous dialogue experience by seamlessly connecting three AI services:

1. **Speech-to-Text (Whisper)** - Converts your voice to text
2. **Language Model (Gemma 3)** - Generates intelligent responses
3. **Text-to-Speech (OpenAudio)** - Converts AI responses back to voice

This enables a **hands-free, voice-driven conversation** with the AI assistant.

---

## âœ¨ Features

### Core Capabilities
- ğŸ™ï¸ **Voice Recording** - Click to start/stop recording with your microphone
- ğŸ’¬ **Real-time Conversation** - Continuous back-and-forth dialogue
- ğŸ”Š **Voice Responses** - AI speaks back to you (optional)
- â–¶ï¸ **Auto-play** - Responses play automatically (optional)
- ğŸ“œ **Conversation History** - Full transcript of your chat
- ğŸ¨ **Visual Interface** - Chat bubble UI with timestamps

### Advanced Features
- ğŸ¤ **Voice Cloning** - Clone a specific voice for AI responses
- âš™ï¸ **System Prompt** - Customize AI personality and behavior
- ğŸ”‡ **Text-only Mode** - Disable voice responses if needed
- ğŸ§¹ **Clear Chat** - Start fresh conversations anytime
- ğŸ“± **Responsive Design** - Works on desktop and mobile

---

## ğŸš€ How to Use

### 1. Access the Live Conversation Tab

Navigate to the frontend at `http://localhost:5174` and click the **"ğŸ™ï¸ Live Conversation"** tab.

### 2. Configure Settings (Optional)

**System Prompt:**
```
You are a helpful AI assistant. Keep your responses concise and conversational.
```
Customize this to change the AI's personality (e.g., "You are a medical expert", "You are a friendly tutor").

**Voice Settings:**
- âœ… **Voice responses** - Enable/disable TTS for AI replies
- âœ… **Auto-play** - Automatically play voice responses
- âœ… **Voice cloning** - Upload reference audio to clone a specific voice

### 3. Start Recording

1. Click the **"ğŸ™ï¸ Start Recording"** button
2. Speak clearly into your microphone
3. Click **"â¹ï¸ Stop Recording"** when finished

### 4. AI Processes Your Message

The system will:
1. **Transcribe** your speech to text (Whisper)
2. **Generate** an intelligent response (Gemma 3)
3. **Synthesize** the response to speech (OpenAudio)
4. **Display** the conversation in chat format

### 5. Continue the Conversation

Repeat steps 3-4 to have a continuous dialogue. The AI remembers the conversation history!

---

## ğŸ¨ User Interface Guide

### Conversation Display

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ’¬ Live Conversation     [Clear chat]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                        â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â† You (right-aligned, green)
â”‚           â”‚ You         3:45 PM  â”‚    â”‚
â”‚           â”‚ What's the weather?  â”‚    â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚  â† Assistant (left-aligned, gray)
â”‚  â”‚ Assistant      3:45 PM   â”‚         â”‚
â”‚  â”‚ I don't have real-time   â”‚         â”‚
â”‚  â”‚ weather data, but I can  â”‚         â”‚
â”‚  â”‚ help you find it!        â”‚         â”‚
â”‚  â”‚ [â–¶ï¸ Play audio]          â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Control Panel

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     [ğŸ™ï¸ Start Recording]              â”‚  â† Click to record
â”‚                                        â”‚
â”‚   Or when recording:                   â”‚
â”‚     [â¹ï¸ Stop Recording] (pulsing)     â”‚
â”‚                                        â”‚
â”‚   Or when processing:                  â”‚
â”‚     âš™ï¸ Processing your message...     â”‚
â”‚                                        â”‚
â”‚   ğŸ“Š 3 message(s) in conversation     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Technical Details

### API Endpoints Used

1. **POST `/v1/speech-to-text`**
   ```json
   FormData:
   - file: audio/webm blob
   
   Response:
   {
     "text": "transcribed text",
     "language": "en"
   }
   ```

2. **POST `/v1/generate`**
   ```json
   Request:
   {
     "prompt": "System prompt + conversation history",
     "max_tokens": 200,
     "temperature": 0.7,
     "top_p": 0.9
   }
   
   Response:
   {
     "text": "AI generated response"
   }
   ```

3. **POST `/v1/text-to-speech`**
   ```json
   Request:
   {
     "text": "AI response text",
     "format": "mp3",
     "sample_rate": 24000,
     "normalize": true,
     "references": ["base64_audio..."] // optional voice cloning
   }
   
   Response:
   {
     "audio_base64": "base64 encoded audio",
     "response_format": "mp3",
     "media_type": "audio/mpeg"
   }
   ```

### Audio Recording

Uses the **Web Audio API** (`navigator.mediaDevices.getUserMedia`):
- Records in WebM format (browser default)
- Captures microphone input
- Stops all tracks after recording

### State Management

```typescript
- messages: Message[]           // Conversation history
- isRecording: boolean          // Recording state
- isProcessing: boolean         // Processing state
- systemPrompt: string          // AI personality
- useVoiceResponse: boolean     // Enable TTS
- autoPlayResponse: boolean     // Auto-play audio
- referenceFiles: File[]        // Voice cloning files
```

### Message Flow

```
User clicks "Start Recording"
  â†“
Browser requests microphone access
  â†“
User speaks â†’ Audio chunks captured
  â†“
User clicks "Stop Recording"
  â†“
Audio blob created (WebM)
  â†“
POST to /v1/speech-to-text (Whisper)
  â†“
Text transcribed
  â†“
Add user message to chat
  â†“
Build conversation context
  â†“
POST to /v1/generate (Gemma LLM)
  â†“
AI response generated
  â†“
[Optional] POST to /v1/text-to-speech (OpenAudio)
  â†“
Audio synthesized
  â†“
Add assistant message to chat
  â†“
[Optional] Auto-play audio
  â†“
Ready for next message
```

---

## ğŸ’¡ Use Cases

### 1. Voice Assistant
```
System Prompt: "You are a helpful personal assistant."
Use Case: Daily task management, reminders, information lookup
```

### 2. Language Tutor
```
System Prompt: "You are a patient language tutor. Correct mistakes gently."
Use Case: Practice speaking a new language
Voice Cloning: Use native speaker voice
```

### 3. Medical Consultation (Demo)
```
System Prompt: "You are a medical AI assistant. Ask relevant health questions."
Use Case: Symptom checker, health advice (demo purposes only)
```

### 4. Customer Service Bot
```
System Prompt: "You are a friendly customer service representative."
Use Case: Answer product questions, handle complaints
Voice Cloning: Use company brand voice
```

### 5. Companion Chat
```
System Prompt: "You are a supportive friend. Be empathetic and encouraging."
Use Case: Mental health support, companionship
```

---

## ğŸ¤ Voice Cloning Setup

### Step 1: Enable Voice Cloning
1. Check **"Voice responses"**
2. Check **"Voice cloning"**
3. Upload section appears

### Step 2: Upload Reference Audio
1. Click **"Choose reference audio"**
2. Select audio file(s):
   - **Duration**: 3-10 seconds
   - **Format**: WAV, MP3, FLAC, OGG
   - **Quality**: Clean speech, no background noise
3. File(s) appear in the list

### Step 3: Start Conversation
All AI responses will use the cloned voice!

**Example:**
```typescript
// Your reference audio: someone speaking Bahasa Indonesia
// AI will respond in that person's voice speaking Bahasa Indonesia
```

---

## âš™ï¸ Configuration Options

### System Prompt Examples

**Professional:**
```
You are a professional AI assistant. Be formal, concise, and accurate.
```

**Friendly:**
```
You are a friendly chatbot. Use casual language and emojis!
```

**Technical:**
```
You are a technical expert. Provide detailed, accurate technical information.
```

**Creative:**
```
You are a creative writing assistant. Be imaginative and descriptive.
```

### Conversation Parameters

| Setting | Default | Description |
|---------|---------|-------------|
| Max tokens | 200 | Length of AI responses |
| Temperature | 0.7 | Creativity (0.0-1.0) |
| Top P | 0.9 | Nucleus sampling |
| Sample rate | 24000 Hz | Audio quality |
| Format | MP3 | Audio format |

---

## ğŸ” Troubleshooting

### Issue: Microphone not working
**Solution:**
- Allow microphone permissions in browser
- Check browser console for errors
- Ensure HTTPS or localhost (required for getUserMedia)

### Issue: No voice responses
**Solution:**
- Check "Voice responses" is enabled
- Verify OpenAudio service is running on port 21251
- Check browser console for TTS errors

### Issue: Poor transcription quality
**Solution:**
- Speak clearly and slowly
- Reduce background noise
- Use a better microphone
- Ensure Whisper service is running

### Issue: Slow responses
**Solution:**
- Backend may be loading models (first request)
- Check Docker container logs
- Verify GPU is being used (if available)
- Reduce max_tokens for faster responses

### Issue: AI forgets context
**Solution:**
- Conversation history is maintained in state
- Check messages array in React DevTools
- Clear chat and start over if needed

### Issue: Voice cloning not working
**Solution:**
- Verify reference audio is 3-10 seconds
- Ensure audio is clear (no noise/echo)
- Check file format is supported
- Try multiple reference samples

---

## ğŸ“Š Performance Tips

### Optimize Response Time
1. **Use GPU** - Enable CUDA for faster processing
2. **Reduce max_tokens** - Shorter responses = faster generation
3. **Disable voice** - Text-only mode is much faster
4. **Warm-up models** - First request is slower (model loading)

### Improve Voice Quality
1. **Better microphone** - USB or headset mic recommended
2. **Quiet environment** - Reduce background noise
3. **Clear speech** - Speak directly into microphone
4. **Good reference audio** - For voice cloning, use high-quality samples

### Manage Memory
1. **Clear chat periodically** - Long conversations use more memory
2. **Limit message history** - Modify code to keep last N messages
3. **Close unused tabs** - Browser memory management

---

## ğŸ¯ Best Practices

### For Users
- ğŸ™ï¸ **Speak clearly** - Better transcription accuracy
- â¸ï¸ **Pause between sentences** - Helps Whisper segment speech
- ğŸ“ **Review transcripts** - Verify what the AI heard
- ğŸ”Š **Use headphones** - Prevent audio feedback loops
- ğŸ§¹ **Clear chat regularly** - Keeps context focused

### For Developers
- âš¡ **Handle errors gracefully** - Show user-friendly messages
- ğŸ”’ **Validate audio input** - Check file size and format
- ğŸ“Š **Monitor latency** - Track each pipeline stage
- ğŸ¨ **Provide feedback** - Show loading states clearly
- ğŸ”§ **Make it configurable** - Let users adjust settings

---

## ğŸš€ Next Steps

### Enhancements You Can Add

1. **Streaming LLM responses** - Use `/v1/generate_stream` for token-by-token display
2. **Interrupt feature** - Allow users to stop AI mid-response
3. **Multiple languages** - Auto-detect and switch languages
4. **Conversation export** - Save chat history to file
5. **Voice commands** - "Stop", "Repeat", "Clear chat" via voice
6. **Emotion detection** - Analyze tone and adjust responses
7. **Background noise reduction** - Pre-process audio before STT
8. **WebSocket mode** - Real-time bidirectional communication
9. **Multi-speaker support** - Identify and track multiple voices
10. **Analytics dashboard** - Track usage, latency, accuracy

---

## ğŸ“š Code Examples

### Customize System Prompt Dynamically

```typescript
const [systemPrompt, setSystemPrompt] = useState(
  "You are a helpful assistant."
);

// Change based on user selection
const setMedicalMode = () => {
  setSystemPrompt("You are a medical AI assistant.");
};

const setTutorMode = () => {
  setSystemPrompt("You are a patient language tutor.");
};
```

### Add Conversation Memory Limit

```typescript
const MAX_HISTORY = 10; // Keep last 10 messages

const conversationHistory = messages
  .slice(-MAX_HISTORY) // Last 10 messages only
  .map((m) => `${m.role === "user" ? "User" : "Assistant"}: ${m.text}`)
  .join("\n");
```

### Custom Audio Format

```typescript
// Record in specific format (if supported)
const mediaRecorder = new MediaRecorder(stream, {
  mimeType: 'audio/webm;codecs=opus'
});
```

### Export Conversation

```typescript
const exportChat = () => {
  const text = messages
    .map(m => `[${m.timestamp.toLocaleString()}] ${m.role}: ${m.text}`)
    .join('\n\n');
  
  const blob = new Blob([text], { type: 'text/plain' });
  const url = URL.createObjectURL(blob);
  const a = document.createElement('a');
  a.href = url;
  a.download = 'conversation.txt';
  a.click();
};
```

---

## ğŸ¬ Demo Scenarios

### Scenario 1: Quick Test
1. Open Live Conversation tab
2. Click "Start Recording"
3. Say: "Hello, can you hear me?"
4. Click "Stop Recording"
5. Wait for AI response
6. Verify transcript and audio playback

### Scenario 2: Medical Consultation (Demo)
```
System Prompt: "You are a medical AI assistant."

User: "I have a headache and feel dizzy."
AI: "I understand. How long have you been experiencing these symptoms?"
User: "About two days now."
AI: "Have you noticed any triggers, like stress or lack of sleep?"
```

### Scenario 3: Language Practice
```
System Prompt: "You are a Spanish tutor. Respond in Spanish."
Voice Cloning: Upload native Spanish speaker audio

User: "Hola, Â¿cÃ³mo estÃ¡s?"
AI: "Â¡Hola! Estoy bien, gracias. Â¿Y tÃº?"
```

---

## ğŸ“ Additional Resources

- **Backend API Docs**: See `backend/README.md` for API details
- **Voice Cloning Guide**: See `backend/TTS_VOICE_CLONING_README.md`
- **Frontend API Integration**: See `frontend/API_INTEGRATION.md`
- **Component Source**: `frontend/src/components/ConversationPanel.tsx`

---

## ğŸ‰ Ready to Chat!

Open the frontend at `http://localhost:5174`, click **"ğŸ™ï¸ Live Conversation"**, and start talking to your AI assistant!

**Enjoy your conversational AI experience!** ğŸš€
