# ==============================================================================
# GemmaVoice Speech API - Environment Configuration
# ==============================================================================

# -----------------------------------------------------------------------------
# API Documentation (Scalar)
# -----------------------------------------------------------------------------
# Use Scalar for modern, beautiful API documentation instead of Swagger UI
USE_SCALAR_DOCS=true

# Documentation and OpenAPI endpoint paths
DOCS_URL=/docs
OPENAPI_URL=/openapi.json

# -----------------------------------------------------------------------------
# Hugging Face & LLM Configuration
# -----------------------------------------------------------------------------
# Token for downloading private/gated models from Hugging Face
HUGGING_FACE_HUB_TOKEN=

# -----------------------------------------------------------------------------
# Whisper (Speech-to-Text) Configuration - FULLY LOCAL
# -----------------------------------------------------------------------------
# Enable local Faster Whisper inference (GPU accelerated)
ENABLE_FASTER_WHISPER=true

# Faster Whisper model size (tiny, base, small, medium, large-v2, large-v3)
# Recommended: base (fast, good quality) or large-v3 (best quality, slower)
FASTER_WHISPER_MODEL_SIZE=base

# Device for Faster Whisper (cuda for GPU, cpu for CPU-only)
FASTER_WHISPER_DEVICE=cuda

# Compute type for Faster Whisper
# GPU options: float16 (fastest), int8_float16 (balanced), int8 (most efficient)
# CPU options: int8, float32
FASTER_WHISPER_COMPUTE_TYPE=float16

# -----------------------------------------------------------------------------
# OpenAI Whisper (Remote) - NOT USED IN FULLY LOCAL MODE
# -----------------------------------------------------------------------------
# Uncomment these if you want to fall back to OpenAI's hosted Whisper
# Set ENABLE_FASTER_WHISPER=false to use remote API instead

# OPENAI_API_KEY=
# OPENAI_API_BASE=https://api.openai.com/v1
# OPENAI_WHISPER_MODEL=gpt-4o-mini-transcribe
# OPENAI_WHISPER_RESPONSE_FORMAT=verbose_json
# OPENAI_TIMEOUT_SECONDS=60

# -----------------------------------------------------------------------------
# OpenAudio (Text-to-Speech) Configuration
# -----------------------------------------------------------------------------
# Base URL of OpenAudio-S1-mini API server
OPENAUDIO_API_BASE=http://localhost:21251

# Optional: API key for OpenAudio authentication
OPENAUDIO_API_KEY=

# TTS endpoint path
OPENAUDIO_TTS_PATH=/v1/tts

# Default audio format (wav, mp3, ogg, flac)
OPENAUDIO_DEFAULT_FORMAT=wav

# Default reference voice ID (optional)
OPENAUDIO_DEFAULT_REFERENCE_ID=

# Enable loudness normalization by default
OPENAUDIO_DEFAULT_NORMALIZE=true

# Network timeout for OpenAudio synthesis (seconds)
OPENAUDIO_TIMEOUT_SECONDS=120

# Number of retries for failed OpenAudio requests
OPENAUDIO_MAX_RETRIES=3

# Default audio sample rate (Hz)
DEFAULT_AUDIO_SAMPLE_RATE=16000

# -----------------------------------------------------------------------------
# Security & Authentication
# -----------------------------------------------------------------------------
# Enable API key authentication
API_KEY_ENABLED=false

# Header name for API key
API_KEY_HEADER_NAME=X-API-Key

# Comma-separated list of valid API keys
API_KEYS=

# -----------------------------------------------------------------------------
# Rate Limiting
# -----------------------------------------------------------------------------
# Enable rate limiting
RATE_LIMIT_ENABLED=false

# Number of requests allowed per window
RATE_LIMIT_REQUESTS=120

# Window duration (seconds)
RATE_LIMIT_WINDOW_SECONDS=60

# Burst multiplier (1.0 = no burst allowance)
RATE_LIMIT_BURST_MULTIPLIER=1.0

# -----------------------------------------------------------------------------
# Observability
# -----------------------------------------------------------------------------
# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# HTTP header for request ID propagation
REQUEST_ID_HEADER=X-Request-ID

# -----------------------------------------------------------------------------
# Docker Compose (for openaudio service)
# -----------------------------------------------------------------------------
# URL of the fish-speech repository (for OpenAudio container)
REPO_URL=https://github.com/fishaudio/fish-speech.git
